import numpy as npimport pandas as pdimport torchimport model1import timefrom Save import fake_data_save#adversarial_loss = torch.nn.MSELoss()adversarial_loss = torch.nn.BCELoss()from torch.autograd import VariableTensor =torch.FloatTensorF = []def train(X_for_generate, gene_number,BATCH_SIZE, Dropout_parm, LR_D, LR_G, gene_name, eopch,N_IDEAS, BL, timestr, TPBL, cancer):    Loss = []    clear = 0    D = model1.discriminator(gene_number)    G = model1.generator(100, Dropout_parm,BATCH_SIZE*gene_number)    D.cuda()    G.cuda()    # 定义判别器和生成器的优化器    opt_D = torch.optim.Adam(D.parameters(), lr=LR_D)    opt_G = torch.optim.Adam(G.parameters(), lr=LR_G)    # gan模型#############结束    # GAN训练    # print(names[0])    best_Loss = 0       for step in range(10000):        # lry  after add        # Adversarial ground truths        real_label = Variable(torch.ones(1))  # 定义真实label为1        fake_label = Variable(torch.zeros(1))        valid = Variable(Tensor(BATCH_SIZE, 1).fill_(1.0), requires_grad=False).cuda()        fake = Variable(Tensor(BATCH_SIZE, 1).fill_(0.0), requires_grad=False).cuda()        # 随机选取BATCH个真实的标签为1的样本        chosen_data = np.random.choice((X_for_generate.shape[0]), size=(1), replace=False)        #print(chosen_data)        # artist_paintings = X_for_generate[chosen_data[0]].view(1, -1)        artist_paintings = X_for_generate[chosen_data[0]]        #print(artist_paintings)        # 使用生成器生成虚假样本        # F.append(torch.randn(1, 10, N_IDEAS, requires_grad=True))        G_ideas = torch.randn(1, N_IDEAS, requires_grad=True)        #print("G_ideas={}".format(G_ideas.size()))        G_paintings = G(G_ideas.cuda()).view(BATCH_SIZE, gene_number)        # = torch.randn(BATCH_SIZE, N_IDEAS, requires_grad=True)        # 使用判别器得到判断的概率        prob_artist1 = D(G_paintings.cuda())        # 生成器损失        # G_loss = torch.mean(torch.log(1. - prob_artist1))        # G_loss = -torch.log(prob_artist1)        # G_loss = 0.5 * torch.mean(prob_artist1) * torch.pow((prob_artist1 - 1.), 2)        # G_loss=criterion(prob_artist1 , fake_label)        G_loss = adversarial_loss(prob_artist1, valid)        #         import pdb        #         pdb.set_trace()        opt_G.zero_grad()        G_loss.backward()        opt_G.step()        prob_artist0 = D(artist_paintings.cuda())        prob_artist1 = D(G_paintings.detach())        # 判别器的损失        # D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1. - prob_artist1))        # D_loss = 0.5 * torch.mean(prob_artist0) * torch.pow((prob_artist0 - 1.), 2) + 0.5 * torch.mean(prob_artist1) * torch.pow(prob_artist1, 2)        # print(torch.mean(G_paintings))        # D_loss = -torch.mean(artist_paintings) * torch.log(prob_artist0) - torch.mean(G_paintings) * torch.log(1. - prob_artist1)        # print(D_loss)        # Measure discriminator's ability to classify real from generated samples        real_loss = adversarial_loss(prob_artist0, valid)        fake_loss = adversarial_loss(prob_artist1, fake)        D_loss = 0.5 * (real_loss + fake_loss)        opt_D.zero_grad()        D_loss.backward()        opt_D.step()        if step % 100 == 0:            #         print(prob_artist0)            print(step)            print(G_loss)            print(D_loss)            Loss.append(D_loss.cpu())            # if D_loss <= 0.1:            #     break    # G = saveG    if eopch == 0:        clear = 1    #Loss0 = np.array(Loss)#    #np.save('processdata/MBGAN/5/{}_{}_{}_Loss'.format(cancer,Dropout_parm,eopch))    torch.save(G, "processdata/MBGAN/save_model/model_" + str(eopch) + ".pth")    G_ideas = torch.randn(1, N_IDEAS, requires_grad=True)    fake_data = G(G_ideas.cuda()).view(BATCH_SIZE, gene_number).cpu().detach().numpy()    print(len(X_for_generate[0]))    savepath = "processdata/MBGAN/5/FakeData_"+cancer+"_"+str(Dropout_parm)+"_"+str(BATCH_SIZE)+"_"+str(BL)+"_"+str(TPBL)+"_"+timestr+".txt"    fake_data_save(fake_data, clear, gene_name , savepath, eopch)    # fake_data = G(torch.randn(1, 244)).detach().numpy()    # print(np.max(fake_data, axis=1))    # print(np.min(fake_data, axis=1))    # savepath = "processdata/MBGAN/FakeData_BLCA.txt"    # fake_data_save(fake_data, 1, savepath, gene_name)    def train_DG(X_for_generate, gene_number,BATCH_SIZE, Dropout_parm, LR_D, LR_G, gene_name, eopch, N_IDEAS):    clear = 0    D = model1.discriminator([10,gene_number])    G = model1.generator([10,gene_number], Dropout_parm)    # 定义判别器和生成器的优化器    opt_D = torch.optim.Adam(D.parameters(), lr=LR_D)    opt_G = torch.optim.Adam(G.parameters(), lr=LR_G)    # gan模型#############结束    # GAN训练    # print(names[0])    for step in range(10000):        # lry  after add        # Adversarial ground truths        valid = Variable(Tensor(1, 1).fill_(1.0), requires_grad=False)        fake = Variable(Tensor(1, 1).fill_(0.0), requires_grad=False)        # 随机选取BATCH个真实的标签为1的样本        for i in range(5):            chosen_data = np.random.choice((X_for_generate.shape[0]), size=(BATCH_SIZE), replace=False)            # print(chosen_data)            artist_paintings = X_for_generate[chosen_data, :]            G_ideas = torch.randn(BATCH_SIZE, N_IDEAS, requires_grad=True)            G_paintings = G(G_ideas)            prob_artist0 = D(artist_paintings)            prob_artist1 = D(G_paintings.detach())            # D_loss = torch.mean(-torch.log(prob_artist0) - torch.log(1. - prob_artist1))            # LSGAN-Dloss            # D_loss = 0.5*torch.mean(artist_paintings)*torch.pow((prob_artist0-1.),2) + 0.5*torch.mean(G_paintings)*torch.pow(prob_artist1, 2)            real_loss = adversarial_loss(prob_artist0, valid)            fake_loss = adversarial_loss(prob_artist1, fake)            D_loss = 0.5*(real_loss + fake_loss)            opt_D.zero_grad()            D_loss.backward(retain_graph=True)            opt_D.step()        # 使用判别器得到判断的概率        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS, requires_grad=True)        G_paintings = G(G_ideas)        prob_artist1 = D(G_paintings)        # 生成器损失        # G_loss = -torch.log(prob_artist1)        #G_loss = torch.mean(torch.log(1. - prob_artist1))        # G_loss=criterion(prob_artist1 , fake_label)        # G_loss = (1/244)*(torch.log(1. - prob_artist1))        G_loss = adversarial_loss(prob_artist1, valid)        # LSGAN-Dloss        # G_loss = 0.5*torch.mean(G_paintings)*torch.pow((prob_artist1 - 1.), 2)        #         import pdb        #         pdb.set_trace()        opt_G.zero_grad()        G_loss.backward()        opt_G.step()        if step % 100 == 0:            #         print(prob_artist0)            print(step)            print("噪声：{}".format(G_ideas))            print("生成样本：{}".format(G_paintings))            print("G返回值：{}".format(prob_artist1))            print("G_loss = {}".format(G_loss))            print("D_loss = {}".format(D_loss))    if eopch == 0:        clear = 1    torch.save(G, "processdata/MBGAN/save_model/model_" + str(eopch) + ".pth")    fake_data = G(torch.randn(1, 244)).detach().numpy()    savepath = "processdata/MBGAN/FakeData_BLCA.txt"    fake_data_save(fake_data, clear, gene_name , savepath, eopch)    # fake_data = G(torch.randn(1, 244)).detach().numpy()    # print(np.max(fake_data, axis=1))    # print(np.min(fake_data, axis=1))    # savepath = "processdata/MBGAN/FakeData_BLCA.txt"    # fake_data_save(fake_data, 1, savepath, gene_name)